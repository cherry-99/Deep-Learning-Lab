{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef405a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reconstruction error is :  tensor(37.6393)\n",
      "Reconstruction loss before setting last singular value to zero :  tensor(33.9710)\n",
      "Reconstruction error after setting last singular value to zero :  tensor(33.9210)\n"
     ]
    }
   ],
   "source": [
    "# Exerceise 1 :  Implementing a matrix factorisation using gradient descent\n",
    "\n",
    "# Exercise 1.1 : Implement gradient based factorisation\n",
    "\n",
    "from typing import Tuple\n",
    "import torch\n",
    "\n",
    "def sgd_factorise (A: torch.Tensor , rank : int , num_epochs=1000, lr=0.01) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    U = torch.rand(list(A.size())[0],rank)\n",
    "    V = torch.rand(list(A.size())[1],rank)\n",
    "    for epoch in range(0, num_epochs):\n",
    "        for r in range(0, list(A.size())[0]):# Check this. Does it start with 0 or 1 becuase the the end value is not inclusive in the loop count.\n",
    "            for c in range(1, list(A.size())[1]):\n",
    "                e = A[r][c] - (U[r,:] * V[c,:].t())\n",
    "                U[r,:] = U[r,:] + lr * e * V[c,:]\n",
    "                V[c,:] = V[c,:] + lr * e * U[r,:]\n",
    "    return U,V\n",
    "\n",
    "# Exercise 1.2 : Factorise and compute reconstruction error\n",
    "\n",
    "A = torch.tensor([[0.3374,0.6005,0.1735] , [3.3359,0.0492,1.8374] , [2.9407,0.5301,2.2620]])\n",
    "U_cap , V_cap = sgd_factorise(A , 2)\n",
    "\n",
    "#print(\"Tensor U cap is : \" , U_cap)\n",
    "#print(\"Tensor V cap is : \" , V_cap)\n",
    "\n",
    "# Computing reconstruction error here. Reconstruction is given by U_cap @ V_cap.t().\n",
    "# The reconstruction error is give by || A - U_cap@V_capt() ||\n",
    "recon_loss = torch.nn.functional.mse_loss(A, U_cap@V_cap.t(), reduction='sum')\n",
    "print(\"The reconstruction error is : \" , recon_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1952171f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2 : Comparison of results to truncated SVD\n",
    "\n",
    "u , s , v = torch.svd(A)\n",
    "#print(u@torch.diag(s)@v)\n",
    "new_recon_loss = torch.nn.functional.mse_loss(A, u@torch.diag(s)@v , reduction='sum')\n",
    "print(\"Reconstruction loss before setting last singular value to zero : \" , new_recon_loss)\n",
    "\n",
    "# Setting the last singular value to 0\n",
    "s[2] = 0\n",
    "#print(s)\n",
    "final_recon_loss = torch.nn.functional.mse_loss(A, u@torch.diag(s)@v , reduction='sum')\n",
    "print(\"Reconstruction error after setting last singular value to zero : \" , final_recon_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3bf20a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated values are: \n",
      "Row 2 , column 1 :  tensor(0.5140)\n",
      "Row 3 , column 2 :  tensor(0.1094)\n",
      "The original matrix is :  tensor([[0.3374, 0.6005, 0.1735],\n",
      "        [0.0000, 0.0492, 1.8374],\n",
      "        [2.9407, 0.0000, 2.2620]])\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3 : Matrix Completion\n",
    "\n",
    "# Exercise 3.1 : Implementation of masked factorisation\n",
    "\n",
    "def sgd_factorise_masked(A: torch.Tensor, M:torch.Tensor, rank:int, num_epochs=1000, lr=0.01) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    U = torch.rand(list(A.size())[0] , rank)\n",
    "    V = torch.rand(list(A.size())[1] , rank)\n",
    "    for epoch in range(1,num_epochs):\n",
    "        for r in range(1, list(A.size())[0]):\n",
    "            for c in range(1, list(A.size())[1]):\n",
    "                if(M[r][c] != 0):\n",
    "                    e = A[r][c] - U[r]@V[c].t()\n",
    "                    U[r] = U[r] + lr*e*V[c]\n",
    "                    V[c] = V[c] + lr*e*U[r]\n",
    "    return U,V\n",
    "                    \n",
    "\n",
    "# Exercise 3.2 : Reconstruct a Matrix\n",
    "\n",
    "A = torch.tensor([[0.3374,0.6005,0.1735] , [0,0.0492,1.8374] , [2.9407,0,2.2620]])\n",
    "M = torch.tensor([[1,1,1],[0,1,1],[1,0,1]])\n",
    "new_U , new_V = sgd_factorise_masked(A,M,2)\n",
    "#print(new_U)\n",
    "#print(new_V)\n",
    "            \n",
    "    \n",
    "reconstructed_matrix = new_U @ new_V.t()\n",
    "print(\"The estimated values are: \")\n",
    "print(\"Row 2 , column 1 : \" , reconstructed_matrix[1][0])\n",
    "print(\"Row 3 , column 2 : \" , reconstructed_matrix[2][1])\n",
    "\n",
    "print(\"The original matrix is : \" , A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1627cc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doubts : For the rank loop, does it start with 1 or does it start with 0. confirm this becuase the number of \n",
    "    # times the loop will run will vary\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
